Tasking execution models are valuable for achieving parallel, heterogeneous, and distributed computing performance. Thanks to the influence of dataflow execution models, tasking enables finer-grain control of the parallelism compared to other execution models such as SPMD. However, most tasking implementations combine the program execution model with its application programming interface into a single definition. More often than not, the API is implemented as part of a programming model that relies on von Neumann execution. Such is the case of the most popular tasking models such as OpenMP, OmpSs, Legion, etc.


This work describes the importance of separating roles between the scheduling language and the computation language. We demonstrate that these two roles are present in all execution models, with some being more explicit than others, but that an explicit distinction could enable further optimizations to be applied to tasking models. We then define a scheduling language and demonstrate how this language can be obtained from the OpenMP tasking execution model. Finally, we list open questions that will need to be answered in order to define an appropriate scheduling language for parallel, heterogeneous, and distributed program execution models.

